# LLM One API

[![Python Version](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

**ç»Ÿä¸€çš„å¤§æ¨¡å‹ä¸­è½¬æœåŠ¡** - å…¼å®¹ OpenAI API æ ¼å¼ï¼Œæ”¯æŒå¤šç§ LLM æä¾›å•†

## âœ¨ æ ¸å¿ƒç‰¹æ€§

| ç‰¹æ€§ | è¯´æ˜ |
|------|------|
| ğŸ”Œ **OpenAI å…¼å®¹** | å®Œå…¨å…¼å®¹ OpenAI API æ ¼å¼ï¼Œæ— ç¼åˆ‡æ¢ |
| âš–ï¸ **è´Ÿè½½å‡è¡¡** | å¤šä¸Šæ¸¸æœåŠ¡å™¨ï¼Œè‡ªåŠ¨æ•…éšœè½¬ç§»ï¼Œæ”¯æŒæƒé‡åˆ†é… |
| ğŸ’° **æˆæœ¬è®¡ç®—** | è‡ªåŠ¨ç»Ÿè®¡ Token ä½¿ç”¨å’Œæˆæœ¬ |
| ğŸ” **è®¤è¯ç³»ç»Ÿ** | çµæ´»çš„ API Key ç®¡ç† |
| ğŸ”Œ **æ’ä»¶åŒ–** | æ˜“äºæ‰©å±•çš„æ’ä»¶ç³»ç»Ÿ |
| ğŸš€ **é«˜æ€§èƒ½** | åŸºäº FastAPIï¼Œæ”¯æŒå¼‚æ­¥å’Œæµå¼å“åº” |

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…

```bash
git clone https://github.com/yourusername/llm-one-api.git
cd llm-one-api
pip install -e .
```

### 2. é…ç½®

åˆ›å»º `config.yaml`ï¼š

```yaml
# è®¤è¯é…ç½®
auth:
  simple:
    api_keys:
      - "sk-your-api-key"

# æ¨¡å‹é…ç½®
models:
  gpt-3.5-turbo:
    api_base: "https://api.openai.com/v1"
    api_key: "sk-your-openai-key"
    timeout: 60

plugins:
  auth: "simple"
  model_route: "config"
  stats: ["log"]
```

### 3. å¯åŠ¨

```bash
python -m llm_one_api.run_server --config config.yaml
```

### 4. ä½¿ç”¨

```python
import openai

openai.api_base = "http://localhost:8000/v1"
openai.api_key = "sk-your-api-key"

response = openai.ChatCompletion.create(
    model="gpt-3.5-turbo",
    messages=[{"role": "user", "content": "Hello!"}]
)
```

æˆ–ä½¿ç”¨ curlï¼š

```bash
curl http://localhost:8000/v1/chat/completions \
  -H "Authorization: Bearer sk-your-api-key" \
  -H "Content-Type: application/json" \
  -d '{"model": "gpt-3.5-turbo", "messages": [{"role": "user", "content": "Hello!"}]}'
```

## ğŸ“– æ–‡æ¡£

| æ–‡æ¡£ | è¯´æ˜ |
|------|------|
| [å¿«é€Ÿå¼€å§‹](docs/QUICKSTART.md) | 5åˆ†é’Ÿå¿«é€Ÿä¸Šæ‰‹æŒ‡å— |
| [è´Ÿè½½å‡è¡¡](docs/LOAD_BALANCING.md) | é…ç½®å¤šä¸Šæ¸¸æœåŠ¡å™¨å’Œè´Ÿè½½å‡è¡¡ |
| [æˆæœ¬ç»Ÿè®¡](docs/STATISTICS.md) | Token ä½¿ç”¨å’Œæˆæœ¬ç»Ÿè®¡ |
| [ä»·æ ¼é…ç½®](docs/MODEL_PRICING.md) | é…ç½®æ¨¡å‹ä»·æ ¼ï¼Œè‡ªåŠ¨è®¡ç®—æˆæœ¬ |
| [é…ç½®ç¤ºä¾‹](examples/config_examples/) | å„ç§åœºæ™¯çš„é…ç½®ç¤ºä¾‹ |
| [æ’ä»¶å¼€å‘](examples/custom_plugin/) | å¼€å‘è‡ªå®šä¹‰æ’ä»¶ |

## ğŸ”§ ä¸»è¦åŠŸèƒ½

### æ”¯æŒçš„æ¥å£

- âœ… `/v1/chat/completions` - èŠå¤©è¡¥å…¨ï¼ˆæ”¯æŒæµå¼ï¼‰
- âœ… `/v1/completions` - æ–‡æœ¬è¡¥å…¨
- âœ… `/v1/embeddings` - æ–‡æœ¬åµŒå…¥
- âœ… `/v1/models` - æ¨¡å‹åˆ—è¡¨

### è´Ÿè½½å‡è¡¡é…ç½®

```yaml
models:
  gpt-3.5-turbo:
    upstreams:
      - api_base: "https://api1.example.com/v1"
        api_key: "key1"
        weight: 2  # 67% æµé‡
      - api_base: "https://api2.example.com/v1"
        api_key: "key2"
        weight: 1  # 33% æµé‡
    load_balance_strategy: "weighted"  # æ”¯æŒ: weighted, round_robin, random
```

### æˆæœ¬ç»Ÿè®¡

```yaml
models:
  gpt-3.5-turbo:
    api_base: "https://api.openai.com/v1"
    api_key: "sk-xxx"
    max_tokens: 4096
    price_per_1k_prompt_tokens: 0.0015   # è¾“å…¥ä»·æ ¼
    price_per_1k_completion_tokens: 0.002  # è¾“å‡ºä»·æ ¼
```

æ—¥å¿—ä¼šè‡ªåŠ¨æ˜¾ç¤ºæˆæœ¬ï¼š
```
ğŸ“Š å“åº”ç»Ÿè®¡ | æ¨¡å‹=gpt-3.5-turbo | è¾“å…¥Token=100 | è¾“å‡ºToken=50 | ğŸ’°æˆæœ¬=$0.000250
```

## ğŸ”Œ æ’ä»¶å¼€å‘

åˆ›å»ºè‡ªå®šä¹‰è®¤è¯æ’ä»¶ï¼š

```python
from llm_one_api.plugins.interfaces import AuthPlugin, AuthResult

class MyAuthPlugin(AuthPlugin):
    async def authenticate(self, api_key: str) -> AuthResult:
        if self.validate_key(api_key):
            return AuthResult(success=True, user_id="user123")
        return AuthResult(success=False, message="Invalid key")
```

åœ¨ `setup.py` ä¸­æ³¨å†Œï¼š

```python
entry_points={
    'llm_one_api.auth': [
        'myauth = my_plugin.auth:MyAuthPlugin',
    ],
}
```

æ›´å¤šç¤ºä¾‹ï¼š[examples/custom_plugin/](examples/custom_plugin/)

## ğŸ—ï¸ æ¶æ„

```
Client â†’ Auth â†’ API Routes â†’ Model Router â†’ Forwarder â†’ Upstream LLM
                                               â†“
                                          Stats Plugin
```

## ğŸ“¦ å‘½ä»¤è¡Œé€‰é¡¹

```bash
python -m llm_one_api.run_server --help

# å¸¸ç”¨é€‰é¡¹ï¼š
--config CONFIG          # é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ï¼šconfig.yamlï¼‰
--host HOST              # ç›‘å¬åœ°å€ï¼ˆé»˜è®¤ï¼š0.0.0.0ï¼‰
--port PORT              # ç›‘å¬ç«¯å£ï¼ˆé»˜è®¤ï¼š8000ï¼‰
--workers WORKERS        # Worker æ•°é‡ï¼ˆé»˜è®¤ï¼š4ï¼‰
--log-level LEVEL        # æ—¥å¿—çº§åˆ«ï¼ˆé»˜è®¤ï¼šINFOï¼‰
--dev                    # å¼€å‘æ¨¡å¼ï¼ˆè‡ªåŠ¨é‡è½½ï¼‰
```

## ğŸ§ª å¼€å‘

```bash
# å®‰è£…å¼€å‘ä¾èµ–
pip install -e ".[dev]"

# è¿è¡Œæµ‹è¯•
pytest

# ä»£ç æ ¼å¼åŒ–
black llm_one_api/
isort llm_one_api/
```

## ğŸ“„ è®¸å¯è¯

[MIT License](LICENSE)

## ğŸ™ è‡´è°¢

- [FastAPI](https://fastapi.tiangolo.com/) - Web æ¡†æ¶
- [httpx](https://www.python-httpx.org/) - HTTP å®¢æˆ·ç«¯
- [loguru](https://github.com/Delgan/loguru) - æ—¥å¿—åº“

---

ğŸ’¡ **æç¤º**: æŸ¥çœ‹ [docs/QUICKSTART.md](docs/QUICKSTART.md) äº†è§£æ›´å¤šè¯¦ç»†ä¿¡æ¯
