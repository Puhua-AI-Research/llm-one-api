"""
FastAPI åº”ç”¨å®ä¾‹

åˆ›å»ºå¹¶é…ç½® FastAPI åº”ç”¨ï¼Œæ³¨å†Œè·¯ç”±å’Œä¸­é—´ä»¶
"""

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from contextlib import asynccontextmanager

from llm_one_api import __version__
from llm_one_api.api.routes import chat, completions, embeddings, models, stats
from llm_one_api.middleware.auth import AuthMiddleware
from llm_one_api.middleware.logging import LoggingMiddleware
from llm_one_api.middleware.rate_limit import RateLimitMiddleware
from llm_one_api.plugins.manager import PluginManager
from llm_one_api.config.settings import get_settings
from llm_one_api.utils.logger import setup_logger

logger = setup_logger(__name__)


@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    # å¯åŠ¨æ—¶
    logger.info("ğŸš€ LLM One API æ­£åœ¨å¯åŠ¨...")
    
    # åŠ è½½é…ç½®
    settings = get_settings()
    logger.info(f"ğŸ“ é…ç½®åŠ è½½å®Œæˆ")
    
    # åˆå§‹åŒ–æ’ä»¶ç³»ç»Ÿ
    plugin_manager = PluginManager(settings)
    await plugin_manager.load_plugins()
    app.state.plugin_manager = plugin_manager
    logger.info(f"ğŸ”Œ æ’ä»¶ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    logger.info(f"âœ… LLM One API v{__version__} å¯åŠ¨æˆåŠŸ")
    
    yield
    
    # å…³é—­æ—¶
    logger.info("ğŸ›‘ LLM One API æ­£åœ¨å…³é—­...")
    await plugin_manager.cleanup()
    logger.info("ğŸ‘‹ LLM One API å·²å…³é—­")


# åˆ›å»º FastAPI åº”ç”¨
app = FastAPI(
    title="LLM One API",
    description="ç»Ÿä¸€çš„å¤§æ¨¡å‹ä¸­è½¬æœåŠ¡ï¼Œå…¼å®¹ OpenAI API",
    version=__version__,
    lifespan=lifespan,
)


# é…ç½® CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ç”Ÿäº§ç¯å¢ƒåº”è¯¥é™åˆ¶å…·ä½“åŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# æ·»åŠ è‡ªå®šä¹‰ä¸­é—´ä»¶
app.add_middleware(LoggingMiddleware)
app.add_middleware(AuthMiddleware)

# æ·»åŠ é™æµä¸­é—´ä»¶ï¼ˆå¦‚æœå¯ç”¨ï¼‰
settings = get_settings()
if settings.rate_limit.get("enabled", False):
    requests_per_minute = settings.rate_limit.get("requests_per_minute", 60)
    app.add_middleware(RateLimitMiddleware, requests_per_minute=requests_per_minute)
    logger.info(f"ğŸš¦ é™æµå·²å¯ç”¨: {requests_per_minute} è¯·æ±‚/åˆ†é’Ÿ")


# æ³¨å†Œè·¯ç”±
app.include_router(chat.router, prefix="/v1", tags=["chat"])
app.include_router(completions.router, prefix="/v1", tags=["completions"])
app.include_router(embeddings.router, prefix="/v1", tags=["embeddings"])
app.include_router(models.router, prefix="/v1", tags=["models"])
app.include_router(stats.router, prefix="/v1", tags=["stats"])


@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "name": "LLM One API",
        "version": __version__,
        "status": "running",
        "docs": "/docs",
    }


@app.get("/health")
async def health():
    """å¥åº·æ£€æŸ¥"""
    return {"status": "healthy"}

