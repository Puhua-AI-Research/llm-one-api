"""
æ—¥å¿—ç»Ÿè®¡æ’ä»¶

å°†è¯·æ±‚å’Œå“åº”ç»Ÿè®¡ä¿¡æ¯è®°å½•åˆ°æ—¥å¿—
"""

import json
from typing import Dict, Any

from llm_one_api.plugins.interfaces.stats import StatsPlugin, RequestInfo, ResponseInfo
from llm_one_api.utils.logger import setup_logger

logger = setup_logger(__name__)


class LogStatsPlugin(StatsPlugin):
    """æ—¥å¿—ç»Ÿè®¡æ’ä»¶"""
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__(config)
        self.log_format = config.get("format", "json")  # json æˆ– text
    
    async def record_request(self, request_info: RequestInfo):
        """
        è®°å½•è¯·æ±‚ä¿¡æ¯åˆ°æ—¥å¿—
        
        Args:
            request_info: è¯·æ±‚ä¿¡æ¯
        """
        if self.log_format == "json":
            log_data = {
                "event": "request",
                "request_id": request_info.request_id,
                "user_id": request_info.user_id,
                "model": request_info.model,
                "endpoint": request_info.endpoint,
                "stream": request_info.stream,
                "timestamp": request_info.timestamp.isoformat(),
            }
            logger.info(json.dumps(log_data, ensure_ascii=False))
        else:
            logger.info(
                f"è¯·æ±‚ | ID={request_info.request_id} | "
                f"ç”¨æˆ·={request_info.user_id} | æ¨¡å‹={request_info.model} | "
                f"æ¥å£={request_info.endpoint} | æµå¼={request_info.stream}"
            )
    
    async def record_response(self, response_info: Dict[str, Any]):
        """
        è®°å½•å“åº”ä¿¡æ¯åˆ°æ—¥å¿—
        
        Args:
            response_info: å“åº”ä¿¡æ¯å­—å…¸ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
        """
        token_usage = response_info.get("token_usage", {})
        metadata = response_info.get("metadata", {})  # ç›´æ¥è·å–ä¼ é€’çš„ metadata
        
        
        if self.log_format == "json":
            # JSON æ ¼å¼ï¼šåŒ…å«å®Œæ•´çš„ token è¯¦ç»†ä¿¡æ¯
            log_data = {
                "event": "response",
                "model": response_info.get("model"),
                "user": response_info.get("user"),
                "endpoint": response_info.get("endpoint"),
                "stream": response_info.get("stream", False),
                "duration": response_info.get("duration", 0),
                "timestamp": response_info.get("timestamp"),
                "tokens": {
                    "prompt_tokens": token_usage.get("prompt_tokens", 0),
                    "completion_tokens": token_usage.get("completion_tokens", 0),
                    "total_tokens": token_usage.get("total_tokens", 0),
                }
            }
            
            # æ·»åŠ æ¨¡å‹é™åˆ¶ä¿¡æ¯
            if metadata:
                log_data["metadata"] = metadata

            
            logger.info(json.dumps(log_data, ensure_ascii=False, default=str))
        else:
            # æ–‡æœ¬æ ¼å¼ï¼šæ¸…æ™°æ˜¾ç¤ºè¾“å…¥å’Œè¾“å‡º token
            prompt_tokens = token_usage.get("prompt_tokens", 0)
            completion_tokens = token_usage.get("completion_tokens", 0)
            total_tokens = token_usage.get("total_tokens", 0)
            
            msg = (
                f"ğŸ“Š å“åº”ç»Ÿè®¡ | "
                f"æ¨¡å‹={response_info.get('model')} | "
                f"ç”¨æˆ·={response_info.get('user')} | "
                f"è€—æ—¶={response_info.get('duration', 0):.2f}s | "
                f"è¾“å…¥Token={prompt_tokens} | "
                f"è¾“å‡ºToken={completion_tokens} | "
                f"æ€»Token={total_tokens} | "
                f"æµå¼={response_info.get('stream')}"
            )
            
            logger.info(msg)
    
    async def initialize(self):
        """åˆå§‹åŒ–æ’ä»¶"""
        logger.info(f"æ—¥å¿—ç»Ÿè®¡æ’ä»¶åˆå§‹åŒ–ï¼Œæ—¥å¿—æ ¼å¼: {self.log_format}")
    
    async def cleanup(self):
        """æ¸…ç†æ’ä»¶"""
        pass

