"""
æœåŠ¡å¯åŠ¨å…¥å£

ä½¿ç”¨ fire åº“æä¾›å‘½ä»¤è¡Œæ¥å£
ä½¿ç”¨ uvicorn å¤šè¿›ç¨‹æ¨¡å¼å¯åŠ¨ FastAPI åº”ç”¨

ä½¿ç”¨æ–¹å¼:
    python -m llm_one_api.run_server --port 8000 --workers 4
    python -m llm_one_api.run_server --dev
"""

import sys
import fire
import uvicorn
from pathlib import Path
from llm_one_api.utils.logger import configure_logger


def main(
    port: int = 8000,
    host: str = "0.0.0.0",
    workers: int = 4,
    config: str = None,
    dev: bool = False,
    reload: bool = False,
    log_level: str = "INFO",
):
    """
    å¯åŠ¨ LLM One API æœåŠ¡
    
    Args:
        port: æœåŠ¡ç«¯å£ï¼Œé»˜è®¤ 8000
        host: ç»‘å®šåœ°å€ï¼Œé»˜è®¤ 0.0.0.0
        workers: å·¥ä½œè¿›ç¨‹æ•°ï¼Œé»˜è®¤ 4ï¼ˆdev æ¨¡å¼ä¸‹å›ºå®šä¸º 1ï¼‰
        config: é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä½¿ç”¨å†…ç½®é…ç½®
        dev: å¼€å‘æ¨¡å¼ï¼Œå¯ç”¨è‡ªåŠ¨é‡è½½ï¼Œå•è¿›ç¨‹
        reload: æ˜¯å¦å¯ç”¨çƒ­é‡è½½ï¼ˆæ–‡ä»¶å˜åŒ–è‡ªåŠ¨é‡å¯ï¼‰
        log_level: æ—¥å¿—çº§åˆ«ï¼Œé»˜è®¤ INFO
    """
    
    # é…ç½®æ—¥å¿—ç³»ç»Ÿ
    if dev:
        configure_logger(level="DEBUG")
    else:
        configure_logger(level=log_level.upper())
    
    # å¦‚æœæŒ‡å®šäº†é…ç½®æ–‡ä»¶ï¼Œè®¾ç½®ç¯å¢ƒå˜é‡
    if config:
        import os
        os.environ["LLM_ONE_API_CONFIG"] = config
        print(f"ä½¿ç”¨é…ç½®æ–‡ä»¶: {config}")
    
    # å¼€å‘æ¨¡å¼é…ç½®
    if dev:
        print("ğŸš€ å¼€å‘æ¨¡å¼å¯åŠ¨...")
        workers = 1
        reload = True
    
    # ç”Ÿäº§æ¨¡å¼é…ç½®
    if workers > 1 and reload:
        print("âš ï¸  å¤šè¿›ç¨‹æ¨¡å¼ä¸æ”¯æŒçƒ­é‡è½½ï¼Œå·²ç¦ç”¨ reload")
        reload = False
    
    print(f"ğŸŒ å¯åŠ¨æœåŠ¡: http://{host}:{port}")
    print(f"ğŸ‘· å·¥ä½œè¿›ç¨‹æ•°: {workers}")
    
    # å¯åŠ¨ uvicorn
    uvicorn.run(
        "llm_one_api.api.app:app",
        host=host,
        port=port,
        workers=workers if not reload else 1,  # reload æ¨¡å¼åªèƒ½å•è¿›ç¨‹
        reload=reload,
        log_level="info",
        access_log=True,
    )


if __name__ == "__main__":
    fire.Fire(main)

